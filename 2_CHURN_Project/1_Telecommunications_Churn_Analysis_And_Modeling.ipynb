{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5a6a29",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Executive-Summary\" data-toc-modified-id=\"Executive-Summary-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Executive Summary</a></span></li><li><span><a href=\"#Initial-Data-Analysis\" data-toc-modified-id=\"Initial-Data-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Initial Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Descriptive-Statistics:\" data-toc-modified-id=\"Descriptive-Statistics:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Descriptive Statistics:</a></span></li><li><span><a href=\"#Clean-and-Save-Data-For-Analysis\" data-toc-modified-id=\"Clean-and-Save-Data-For-Analysis-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Clean and Save Data For Analysis</a></span></li></ul></li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Pandas_Profiling_Module\" data-toc-modified-id=\"The-Pandas_Profiling_Module-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Pandas_Profiling_Module</a></span></li><li><span><a href=\"#Histograms-Of-Clean-Churn-Data\" data-toc-modified-id=\"Histograms-Of-Clean-Churn-Data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Histograms Of Clean Churn Data</a></span></li><li><span><a href=\"#Pearson's-Pairwise-Correlation\" data-toc-modified-id=\"Pearson's-Pairwise-Correlation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Pearson's Pairwise Correlation</a></span></li><li><span><a href=\"#Feature-Importance-Using-Logit-P-Values\" data-toc-modified-id=\"Feature-Importance-Using-Logit-P-Values-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Feature Importance Using Logit P-Values</a></span></li><li><span><a href=\"#Feature-Importances-Obtained-From-Logit-Coefficients\" data-toc-modified-id=\"Feature-Importances-Obtained-From-Logit-Coefficients-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Feature Importances Obtained From Logit Coefficients</a></span></li><li><span><a href=\"#Exploring-Correlation\" data-toc-modified-id=\"Exploring-Correlation-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Exploring Correlation</a></span></li></ul></li><li><span><a href=\"#Logistic-Regression-Model\" data-toc-modified-id=\"Logistic-Regression-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Logistic Regression Model</a></span></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>KNN</a></span></li><li><span><a href=\"#Appendices\" data-toc-modified-id=\"Appendices-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Appendices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlation-Coefficients-of-Features\" data-toc-modified-id=\"Correlation-Coefficients-of-Features-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Correlation Coefficients of Features</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb199aff",
   "metadata": {},
   "source": [
    "# 1_Telecommunications_Churn_Analysis_And_Modeling\n",
    "\n",
    "To:&nbsp;&nbsp;&nbsp;&nbsp; Magnimind\n",
    "\n",
    "From: Matt Curcio, matt.curcio.ri@gmail.com\n",
    "\n",
    "Date: 2022-12-27\n",
    "\n",
    "Re:&nbsp;&nbsp;&nbsp; Churn Analysis Using 'churn.all2'\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    ">*Note: This report describes work for the hypothetical telecommunications company, AD&D.*\n",
    "\n",
    "1. The loss of AD&D customers to competition is a constant problem. The dataset ('churn.all2') obtained on Nov. 5, 2022, from marketing data, shows that 14.1% (approximately 1 out of 7) of AD&D customers leave per quarter. It is hoped that AD&D can reduce its advertising budget of $10 million by 25% per quarter by reducing churn. \n",
    "\n",
    "|  Churn Rate | Counts | Percent |\n",
    "|:------------|-------:|--------:|\n",
    "|     Churned |    707 |   14.1% |\n",
    "|    No-Churn |   4293 |   85.9% |\n",
    "|       Total |   5000 |  100.0% |\n",
    "\n",
    "\n",
    "2. The purpose of this analysis is determine which factors are important for keeping customers and to model the dataset to better understand if current advertising campaigns are helpful and keep loyal customers. Models were investigated and the top three are:\n",
    "\n",
    "\n",
    "3. This analysis aims to determine: \n",
    "\n",
    "    - What factors/features are important for keeping customers. \n",
    "    - What statistical model best describes the dataset so that marketing dollars can be spent wisely and which advertising campaigns are most effective.\n",
    "\n",
    "\n",
    "\n",
    "4. From the 18 features investigated, five had the lasrgest impact:\n",
    "\n",
    "    - one\n",
    "\n",
    "\n",
    "\n",
    "**Conclusions**\n",
    "\n",
    "\n",
    "1. Customer retention can be achieved with good customer service and products.\n",
    "\n",
    "\n",
    "|         Model | Accuracy | Recall | Precision |     F2 |\n",
    "|:--------------|---------:|-------:|----------:|-------:|\n",
    "|         Logit |      707 |  14.1% |       107 |  11.1% |\n",
    "| Random Forest |     4293 |  85.9% |       701 |  11.1% |\n",
    "|       XGBoost |     5000 |  85.9% |       717 |  11.1% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d5162",
   "metadata": {},
   "source": [
    "##  Initial Data Analysis\n",
    "\n",
    "- This churn data used was provided Yasin Ceran, PhD on November 5, 2020. \n",
    "\n",
    "**NOTE 1.** *I use a new report format. I have carried out all this work by experimenting with one Jupyter Notebook at a time. Therefore, I call each notebook individually within this 'master-file'. This emphasises the results and conclusions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405225e",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "**NOTE 2.** Question marks `?` were found in `churn.all2` therefore use `pd.read_csv(file_name, na_values='?')`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f05c53",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import add_constant as add_constant\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# SKLearn Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"churn.all2\"\n",
    "\n",
    "df = pd.read_csv(filename, na_values='?') # file=churn.all2 contains '?' instead of Null or Nan.\n",
    "\n",
    "df.fillna(method='ffill', inplace=True) # Forward fill Nan\n",
    "\n",
    "df = df.drop('phone_number', axis=1)  # Drop column 'phone_number'.\n",
    "\n",
    "print(55*'=')\n",
    "print(f'\\nFile \"{filename}\" has ', df.shape[0], 'Observations &', df.shape[1], 'features.\\n')\n",
    "print(f'Column names are:\\n\\n', df.columns)\n",
    "\n",
    "print('\\nDataset contains ANY NULL values:', df.isnull().values.any())\n",
    "print('\\nDataset contains ANY NaN values:', df.isna().values.any(), '\\n')\n",
    "print(55 * '=')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4236039",
   "metadata": {},
   "source": [
    "### Descriptive Statistics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd7b04",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('\\nDescriptive statistics of np.numeric data')\n",
    "df.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nCounts of object data.')\n",
    "df.describe(include=[object]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666311a6",
   "metadata": {},
   "source": [
    "### Clean and Save Data For Analysis\n",
    "\n",
    "**NOTE 3.** \n",
    "- Based on correlation coefficients (data not shown here) and discussions with the Yasin Ceran, it was decided `state`,`area_code`,`phone_number` will not be used in this analysis.\n",
    "\n",
    "- Convert features `intl_plan`, `voice_mail_plan` from {yes, no} to integers {0,1}.  \n",
    "\n",
    "- Convert feature `churned` from {True, False} to integers {0,1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f991cc5",
   "metadata": {
    "code_folding": [
     9,
     11,
     13
    ]
   },
   "outputs": [],
   "source": [
    "file_read = \"churn.all2\"\n",
    "file_saved = \"mcc_clean_churn.csv\"\n",
    "\n",
    "df = pd.read_csv(file_read, na_values='?') # file=churn.all2 contains '?' instead of Null or Nan.\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "df.drop(['state', 'phone_number', 'area_code'], axis=1, inplace=True)  # drop a column based on name\n",
    "\n",
    "df['intl_plan'] = df['intl_plan'].apply(\n",
    "    lambda x: 0 if x.strip() == 'no' else 1).astype('int8')\n",
    "df['voice_mail_plan'] = df['voice_mail_plan'].apply(\n",
    "    lambda x: 0 if x.strip() == 'no' else 1).astype('int8')\n",
    "df['churned'] = df['churned'].apply(\n",
    "    lambda x: 0 if x.strip() == 'False.' else 1).astype('int8')\n",
    "\n",
    "# Change column names for clarity\n",
    "df.columns = ['Act_Len','Int_Plan','VM_Plan','Num_VM','T_D_Min','T_D_Calls','T_D_Charge','T_E_Min',\n",
    "              'T_E_Calls','T_E_Charge','T_N_Min','T_N_Calls','T_N_Charge','T_I_Min','T_I_Calls',\n",
    "              'T_I_Charge','Num_Srv_Calls','Churned']\n",
    "\n",
    "# Save Cleaned Data\n",
    "df.to_csv(file_saved)\n",
    "\n",
    "print(55*'=')\n",
    "print(f'\\nFile \"{file_saved}\" has ', df.shape[0], 'Observations &', df.shape[1], 'features.\\n')\n",
    "print(f'Column names are:\\n\\n', df.columns)\n",
    "\n",
    "print('\\nDataset contains ANY NULL values:', df.isnull().values.any())\n",
    "print('\\nDataset contains ANY NaN values:', df.isna().values.any(), '\\n')\n",
    "print(55 * '=')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5238aea",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e610dc6",
   "metadata": {},
   "source": [
    "### The Pandas_Profiling_Module\n",
    "\n",
    "**https://pypi.org/project/pandas-profiling/**\n",
    "        \n",
    "The Pandas Profiling Module is very easy to use and retreive information from. One negative about the module is that it generated >400 pages of PDF data. However, the information rate per page was low. \n",
    "\n",
    "The Pandas Profiling Module has some *interactive Interaction diagrams*. **See Appendix 1**\n",
    "\n",
    "- For example, the *Pandas Profiling Module* **provided 15 Alerts for the raw data \"churn.all2\"**.\n",
    "\n",
    "\n",
    "| Alert | Message |\n",
    "|:------|:--------|\n",
    "| state has a high cardinality: 51 distinct values | High cardinality |\n",
    "| phone_number has a high cardinality: 5000 distinct values | High cardinality |\n",
    "| total_eve_charge has a high cardinality: 1660 distinct values | High cardinality |\n",
    "| number_vmail_messages is highly overall correlated with voice_mail_plan | High correlation |\n",
    "| total_day_minutes is highly overall correlated with total_day_charge | High correlation |\n",
    "| total_day_charge is highly overall correlated with total_day_minutes | High correlation |\n",
    "| total_night_minutes is highly overall correlated with total_night_charge | High correlation |\n",
    "| total_night_charge is highly overall correlated with total_night_minutes | High correlation |\n",
    "| total_intl_minutes is highly overall correlated with total_intl_charge | High correlation |\n",
    "| total_intl_charge is highly overall correlated with total_intl_minutes | High correlation |\n",
    "| voice_mail_plan is highly overall correlated with number_vmail_messages | High correlation |\n",
    "| phone_number is uniformly distributed | Uniform |\n",
    "| phone_number has unique values | Unique |\n",
    "| number_vmail_messages has 3678 (73.6%) zeros | Zeros |\n",
    "| number_customer_service_calls has 1023 (20.5%) zeros | Zeros |\n",
    "\n",
    "\n",
    "**NOTE 5.** See Appdendix for more information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07edc1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Histograms Of Clean Churn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921e18f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run 2_Histograms_Of_Clean_Churn_Data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fa7f2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pearson's Pairwise Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63591a2",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run 3_Pearson_s_Pairwise_Correlation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686ceb1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**NOTE 4.**\n",
    "    \n",
    "- With respect to **'Churned': Int_Plan, VM_Plan, T_D_Min, & Num_Srv_Calls have the highest correlations**.\n",
    "\n",
    "\n",
    "- The five strongly red correlation coefficients near the hypotenuse are collinear variables.\n",
    "\n",
    "  - 'VM_Plan':'Num_VM'\n",
    "  - 'T_D_Minutes':'T_D_Charge'\n",
    "  - 'T_E_Min':'T_E_Charge'\n",
    "  - 'T_N_Min':'T_N_Charge'\n",
    "  - 'T_I_Min':'T_I_Charge'\n",
    "  \n",
    "  \n",
    "- Consider removing All Total Charges:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b07164",
   "metadata": {},
   "source": [
    "### Feature Importance Using Logit P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mcc_clean_churn.csv\")\n",
    "\n",
    "df_constant = add_constant(df)\n",
    "\n",
    "stats.chisqprob = lambda chisq, df: st.chi2.sf(chisq, df)\n",
    "cols = df_constant.columns[:-1]\n",
    "\n",
    "##\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=100)\n",
    "pipe = Pipeline([('Scale01', MinMaxScaler()), ('Logit', LogisticRegression(max_iter=100))])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "##\n",
    "\n",
    "model = sm.Logit(df.Churned, df_constant[cols])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e434c",
   "metadata": {},
   "source": [
    "**Top Five Features Obtained From Logit P-Values**\n",
    "\n",
    "- These features were chosen because their Z-score probabilities were $\\alpha < 0.05$.\n",
    "\n",
    "- These five features will be added to a Logistic Regression model for further model building.\n",
    "\n",
    "| No. |      Feature | Z-Score | Pr(Z-score) |\n",
    "|----:|:-------------|--------:|------------:|\n",
    "|   1 |     Int_Plan |  17.340 |         0.0 |\n",
    "|   2 |      VM_Plan |   -4.52 |         0.0 |\n",
    "|   3 |       Num_VM |    2.40 |       0.016 |\n",
    "|   4 |  T_Int_Calls |  -3.539 |         0.0 |\n",
    "|   5 |Num_Srv_Calls |  15.688 |         0.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20061e3",
   "metadata": {},
   "source": [
    "### Feature Importances Obtained From Logit Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Churned', axis=1)\n",
    "y = df['Churned']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=100)\n",
    "pipe = Pipeline([('Scale01', MinMaxScaler()), ('Logit', LogisticRegression(max_iter=100))])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': x_train.columns,\n",
    "    'Importance': model.coef_[0]\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323baaa",
   "metadata": {},
   "source": [
    "**Top 5 Featutres Listed in Order Of Importance**\n",
    "\n",
    "| No. |      Feature |\n",
    "|----:|-------------:|\n",
    "|   1 | Num_Srv_Calls |\n",
    "|   2 |     Int_Plan |\n",
    "|   3 |      T_D_Min |\n",
    "|   4 |     T_D_Cost |\n",
    "|   5 |      VM_Plan |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a4cb4",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep ONLY Core 8\n",
    "core8 = df[[\n",
    "    'Int_Plan', 'VM_Plan', 'Num_VM', 'Num_Srv_Calls', \n",
    "    'T_D_Cost','T_E_Calls','T_Nt_Calls', 'T_Int_Calls'\n",
    "]]\n",
    "core8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3097ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = core8\n",
    "y = df['Churned']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=100)\n",
    "\n",
    "\n",
    "pipe = Pipeline([('Scale01', MinMaxScaler()), ('Logit', LogisticRegression(max_iter=100))])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "pipe.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ebaf8",
   "metadata": {},
   "source": [
    "NOTE X: Out of curiosity I checked if there was a difference between three groupings, Minutes, Calls, or Cost.<br>I found Calls had the highest score.\n",
    "\n",
    "| Grouping | Score |\n",
    "|---------:|------:|\n",
    "| min | 0.8552 |\n",
    "| calls | **0.8584** |\n",
    "| cost | 0.8552 |\n",
    "| 'T_D_Cost','T_E_Calls','T_Nt_Calls', 'T_Int_Calls' | 0.8528 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96451fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#lr = LogisticRegression(penalty='l2', C=0.4)\n",
    "#lr.fit(x_train, y_train)\n",
    "#pred = model.predict(x_test)\n",
    "#from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4563608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred=logreg.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b36210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333df92",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Churned', axis=1)\n",
    "y = df['Churned']\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=100)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "sx_train = scaler.fit_transform(x_train, y_train)\n",
    "sx_test = scaler.fit_transform(x_test, y_test)\n",
    "\n",
    "knn.fit(sx_train, y_train)\n",
    "knn.score(sx_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee77517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "pipe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2dd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'knn__n_neighbors': np.arange(1, 15, 2)}\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(x_train, y_train)\n",
    "grid.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b08fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf94016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8164ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0eaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a624eb6",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576ebdb",
   "metadata": {},
   "source": [
    "### Pandas Profiling Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8836f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Appendix_1_EDA_Using_Pandas_Profiling_Module.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6476c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
